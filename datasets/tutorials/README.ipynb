{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0abab29a-c250-4e79-b30b-5c59c972a9ac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8251aab-3918-4b8f-9b59-360a8a0e4803",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pushd .; cd ../../; poetry install --no-dev; popd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7d2f76-919c-4e45-96a7-e92d12288c70",
   "metadata": {},
   "source": [
    "# Run the Tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981f3349-6171-4471-aa7e-7c7d081a2bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n",
      "\u001b[35m\u001b[1mMetaflow zg.post1.2-7+git6ecef60\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mHelloDatasetFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:talebz\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:14.445 \u001b[0m\u001b[1mWorkflow starting (run-id 1652888894410378):\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:14.468 \u001b[0m\u001b[32m[1652888894410378/start/1 (pid 27711)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:15.738 \u001b[0m\u001b[32m[1652888894410378/start/1 (pid 27711)] \u001b[0m\u001b[22m/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:16.856 \u001b[0m\u001b[32m[1652888894410378/start/1 (pid 27711)] \u001b[0m\u001b[22msaving data_frame:\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:17.178 \u001b[0m\u001b[32m[1652888894410378/start/1 (pid 27711)] \u001b[0m\u001b[22mfrom pyarrow import HadoopFileSystem\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:17.178 \u001b[0m\u001b[32m[1652888894410378/start/1 (pid 27711)] \u001b[0m\u001b[22mregion  zpid\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:17.178 \u001b[0m\u001b[32m[1652888894410378/start/1 (pid 27711)] \u001b[0m\u001b[22mA     1\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:17.178 \u001b[0m\u001b[32m[1652888894410378/start/1 (pid 27711)] \u001b[0m\u001b[22mA     2\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:17.178 \u001b[0m\u001b[32m[1652888894410378/start/1 (pid 27711)] \u001b[0m\u001b[22mA     3\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:17.179 \u001b[0m\u001b[32m[1652888894410378/start/1 (pid 27711)] \u001b[0m\u001b[22mB     4\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:17.179 \u001b[0m\u001b[32m[1652888894410378/start/1 (pid 27711)] \u001b[0m\u001b[22mB     5\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:17.179 \u001b[0m\u001b[32m[1652888894410378/start/1 (pid 27711)] \u001b[0m\u001b[22mB     6\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:17.184 \u001b[0m\u001b[32m[1652888894410378/start/1 (pid 27711)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:17.195 \u001b[0m\u001b[32m[1652888894410378/end/2 (pid 27722)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:18.375 \u001b[0m\u001b[32m[1652888894410378/end/2 (pid 27722)] \u001b[0m\u001b[22m/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:19.347 \u001b[0m\u001b[32m[1652888894410378/end/2 (pid 27722)] \u001b[0m\u001b[22mI have dataset\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:19.415 \u001b[0m\u001b[32m[1652888894410378/end/2 (pid 27722)] \u001b[0m\u001b[22mself.output_dataset=BatchDataset(self.name='HelloDataset',self.key=None,self.partition_by='region',self.run_id='1652888894410378',self.columns=None,self.mode=READ_WRITE,self.path=None,self._path='/Users/talebz/src/zda/datasets/.metaflow/datastore/HelloDatasetFlow/hello_dataset')\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:19.415 \u001b[0m\u001b[32m[1652888894410378/end/2 (pid 27722)] \u001b[0m\u001b[22mself.output_dataset.to_pandas(partitions=dict(region=\"A\")):\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:19.417 \u001b[0m\u001b[32m[1652888894410378/end/2 (pid 27722)] \u001b[0m\u001b[22mzpid region\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:19.771 \u001b[0m\u001b[32m[1652888894410378/end/2 (pid 27722)] \u001b[0m\u001b[22mfrom pyarrow import HadoopFileSystem\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:19.771 \u001b[0m\u001b[32m[1652888894410378/end/2 (pid 27722)] \u001b[0m\u001b[22m1      A\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:19.771 \u001b[0m\u001b[32m[1652888894410378/end/2 (pid 27722)] \u001b[0m\u001b[22m2      A\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:19.772 \u001b[0m\u001b[32m[1652888894410378/end/2 (pid 27722)] \u001b[0m\u001b[22m3      A\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:19.774 \u001b[0m\u001b[32m[1652888894410378/end/2 (pid 27722)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:19.776 \u001b[0m\u001b[1mDone!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python 0_hello_dataset_flow.py --no-pylint run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab81a300-04a7-4b2b-9acc-bbe128b1cdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n",
      "\u001b[35m\u001b[1mMetaflow zg.post1.2-7+git6ecef60\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mInputOutputDatasetFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:talebz\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[31m\u001b[1m    Pylint couldn't analyze your code.\n",
      "    \tPylint exception: AttributeError(\"module 'isort' has no attribute 'SortImports'\")\u001b[K\u001b[0m\u001b[31m\u001b[1m\u001b[0m\n",
      "\u001b[31m\u001b[1m    Skipping Pylint checks.\u001b[K\u001b[0m\u001b[31m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:35.010 \u001b[0m\u001b[1mWorkflow starting (run-id 1652888914990316):\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:35.017 \u001b[0m\u001b[32m[1652888914990316/start/1 (pid 27754)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:36.196 \u001b[0m\u001b[32m[1652888914990316/start/1 (pid 27754)] \u001b[0m\u001b[22m/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:37.328 \u001b[0m\u001b[32m[1652888914990316/start/1 (pid 27754)] \u001b[0m\u001b[22mself.program_name=None, dataset.program_name='HelloDatasetFlow'\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:37.705 \u001b[0m\u001b[32m[1652888914990316/start/1 (pid 27754)] \u001b[0m\u001b[22mfrom pyarrow import HadoopFileSystem\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:37.710 \u001b[0m\u001b[32m[1652888914990316/start/1 (pid 27754)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:37.725 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:39.035 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.103 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22mI have dataset\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.177 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22mself.output_dataset=BatchDataset(self.name='OutputDataset',self.key=None,self.partition_by='date_key,region',self.run_id='1652888914990316',self.columns=None,self.mode=READ_WRITE,self.path=None,self._path='/Users/talebz/src/zda/datasets/.metaflow/datastore/InputOutputDatasetFlow/output_dataset')\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.177 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22mself.my_dataset.to_pandas:\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.194 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22mzpid   date_key region\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.195 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m1 10-01-2021      A\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.195 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m2 10-01-2021      A\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.195 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m3 10-01-2021      A\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.195 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m4 10-01-2021      B\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.195 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m5 10-01-2021      B\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.195 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m6 10-01-2021      B\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.195 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22mzpid region\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.494 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22mfrom pyarrow import HadoopFileSystem\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.494 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m1      A\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.495 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m2      A\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.495 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m3      A\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.495 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m4      B\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.495 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m5      B\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.495 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[22m6      B\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.498 \u001b[0m\u001b[32m[1652888914990316/end/2 (pid 27767)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:40.500 \u001b[0m\u001b[1mDone!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python 1_input_output_flow.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b4c12-f036-446c-9f86-64558e692c8a",
   "metadata": {},
   "source": [
    "# The Consistent Flow!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42c2d4-8b60-4b68-b6f6-488f0ea5bada",
   "metadata": {},
   "source": [
    "### Default Context is BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faec4f91-c21e-44a3-9fe3-2de184a81886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n",
      "\u001b[35m\u001b[1mMetaflow zg.post1.2-7+git6ecef60\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mConsistentFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:talebz\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:54.821 \u001b[0m\u001b[1mWorkflow starting (run-id 1652888934812665):\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:54.826 \u001b[0m\u001b[32m[1652888934812665/start/1 (pid 27803)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:56.504 \u001b[0m\u001b[32m[1652888934812665/start/1 (pid 27803)] \u001b[0m\u001b[22m/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:57.756 \u001b[0m\u001b[32m[1652888934812665/start/1 (pid 27803)] \u001b[0m\u001b[22mself.hello_ds=BatchDataset(self.name='HelloDs',self.key=None,self.partition_by=None,self.run_id=None,self.columns='key,value',self.mode=READ_WRITE,self.path=None,self._path=None)\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:57.854 \u001b[0m\u001b[32m[1652888934812665/start/1 (pid 27803)] \u001b[0m\u001b[22mself.hello_ds._executor.context=BATCH\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:57.854 \u001b[0m\u001b[32m[1652888934812665/start/1 (pid 27803)] \u001b[0m\u001b[22mtype(read_df)=<class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:57.860 \u001b[0m\u001b[32m[1652888934812665/start/1 (pid 27803)] \u001b[0m\u001b[22mread_df=      key  value\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:58.233 \u001b[0m\u001b[32m[1652888934812665/start/1 (pid 27803)] \u001b[0m\u001b[22mfrom pyarrow import HadoopFileSystem\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:58.234 \u001b[0m\u001b[32m[1652888934812665/start/1 (pid 27803)] \u001b[0m\u001b[22m0  secret     42\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:58.237 \u001b[0m\u001b[32m[1652888934812665/start/1 (pid 27803)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:58.255 \u001b[0m\u001b[32m[1652888934812665/end/2 (pid 27823)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:48:59.799 \u001b[0m\u001b[32m[1652888934812665/end/2 (pid 27823)] \u001b[0m\u001b[22m/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:49:01.225 \u001b[0m\u001b[32m[1652888934812665/end/2 (pid 27823)] \u001b[0m\u001b[22mdone!\u001b[0m\n",
      "\u001b[35m2022-05-18 08:49:01.528 \u001b[0m\u001b[32m[1652888934812665/end/2 (pid 27823)] \u001b[0m\u001b[22mfrom pyarrow import HadoopFileSystem\u001b[0m\n",
      "\u001b[35m2022-05-18 08:49:01.532 \u001b[0m\u001b[32m[1652888934812665/end/2 (pid 27823)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:49:01.541 \u001b[0m\u001b[1mDone!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python 5_consistent_flow.py --no-pylint run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d18870-81bd-4087-9b3d-d31551deac1c",
   "metadata": {},
   "source": [
    "### Try it with ONLINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "995b046c-eda7-40d5-a7b5-a25a484cc137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n",
      "\u001b[35m\u001b[1mMetaflow zg.post1.2-7+git6ecef60\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mConsistentFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:talebz\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-05-18 08:57:58.598 \u001b[0m\u001b[1mWorkflow starting (run-id 1652889478587785):\u001b[0m\n",
      "\u001b[35m2022-05-18 08:57:58.606 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:57:59.824 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[22m/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:00.739 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[22mself.hello_ds=Dataset(self.name='HelloDs',self.mode=READ_WRITE,self.key=None,self.columns='key,value')\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:00.745 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[22mself.hello_ds._executor.context=ONLINE\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:00.745 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[22m<class 'NoneType'> self.keys=None\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:00.749 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[22mtype(read_df)=<class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:00.749 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[22mread_df=      key  value\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:00.999 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[22mfrom pyarrow import HadoopFileSystem\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:00.999 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[22m0   first      1\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:00.999 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[22m1  second      2\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:01.000 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[22m2   third      3\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:01.000 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[22m3  fourth      4\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:01.000 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[22m4  secret     42\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:01.003 \u001b[0m\u001b[32m[1652889478587785/start/1 (pid 29480)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:01.012 \u001b[0m\u001b[32m[1652889478587785/end/2 (pid 29500)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:02.134 \u001b[0m\u001b[32m[1652889478587785/end/2 (pid 29500)] \u001b[0m\u001b[22m/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:03.025 \u001b[0m\u001b[32m[1652889478587785/end/2 (pid 29500)] \u001b[0m\u001b[22mdone!\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:03.306 \u001b[0m\u001b[32m[1652889478587785/end/2 (pid 29500)] \u001b[0m\u001b[22mfrom pyarrow import HadoopFileSystem\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:03.309 \u001b[0m\u001b[32m[1652889478587785/end/2 (pid 29500)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-05-18 08:58:03.311 \u001b[0m\u001b[1mDone!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!CONTEXT=ONLINE python 5_consistent_flow.py --no-pylint run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3a00b-ddcf-440e-a11a-913d159c8a07",
   "metadata": {},
   "source": [
    "## Try parameterized Dataset with columns=\"value\"\n",
    "### note: default is CONTEXT=BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bf63c5b-5b0b-417d-bbcf-1af36b337f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n",
      "\u001b[35m\u001b[1mMetaflow zg.post1.2-7+git6ecef60\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mConsistentFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:talebz\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:41.398 \u001b[0m\u001b[1mWorkflow starting (run-id 1652889821383587):\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:41.409 \u001b[0m\u001b[32m[1652889821383587/start/1 (pid 30311)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:42.846 \u001b[0m\u001b[32m[1652889821383587/start/1 (pid 30311)] \u001b[0m\u001b[22m/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:43.944 \u001b[0m\u001b[32m[1652889821383587/start/1 (pid 30311)] \u001b[0m\u001b[22mself.hello_ds=BatchDataset(self.name='HelloDs',self.key=None,self.partition_by=None,self.run_id=None,self.columns='value',self.mode=READ_WRITE,self.path=None,self._path=None)\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:43.944 \u001b[0m\u001b[32m[1652889821383587/start/1 (pid 30311)] \u001b[0m\u001b[22mself.hello_ds._executor.context=BATCH\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:44.017 \u001b[0m\u001b[32m[1652889821383587/start/1 (pid 30311)] \u001b[0m\u001b[22mtype(read_df)=<class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:44.022 \u001b[0m\u001b[32m[1652889821383587/start/1 (pid 30311)] \u001b[0m\u001b[22mread_df=   value\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:44.365 \u001b[0m\u001b[32m[1652889821383587/start/1 (pid 30311)] \u001b[0m\u001b[22mfrom pyarrow import HadoopFileSystem\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:44.366 \u001b[0m\u001b[32m[1652889821383587/start/1 (pid 30311)] \u001b[0m\u001b[22m0     42\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:44.370 \u001b[0m\u001b[32m[1652889821383587/start/1 (pid 30311)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:44.381 \u001b[0m\u001b[32m[1652889821383587/end/2 (pid 30316)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:45.633 \u001b[0m\u001b[32m[1652889821383587/end/2 (pid 30316)] \u001b[0m\u001b[22m/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:46.670 \u001b[0m\u001b[32m[1652889821383587/end/2 (pid 30316)] \u001b[0m\u001b[22mdone!\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:46.953 \u001b[0m\u001b[32m[1652889821383587/end/2 (pid 30316)] \u001b[0m\u001b[22mfrom pyarrow import HadoopFileSystem\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:46.956 \u001b[0m\u001b[32m[1652889821383587/end/2 (pid 30316)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-05-18 09:03:46.958 \u001b[0m\u001b[1mDone!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Try parameterized Dataset with columns=\"value\"\n",
    "# note: default is CONTEXT=BATCH\n",
    "!python 5_consistent_flow.py --no-pylint run --hello_ds '{\"name\": \"HelloDs\", \"mode\": \"READ_WRITE\", \"columns\": \"value\", \"options\":{\"type\":\"BatchOptions\"}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e263a7-def1-4a32-9815-798ff05ed6de",
   "metadata": {},
   "source": [
    "### Try it with ONLINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d907fe1c-72c3-455d-8616-455983e7daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n",
      "\u001b[35m\u001b[1mMetaflow zg.post1.2-7+git6ecef60\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mConsistentFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:talebz\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:22.995 \u001b[0m\u001b[1mWorkflow starting (run-id 1652893702986250):\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:23.001 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:24.204 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[22m/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.239 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[22mself.hello_ds=Dataset(self.name='HelloDs',self.mode=READ_WRITE,self.key=None,self.columns='key,value')\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.246 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[22mself.hello_ds._executor.context=ONLINE\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.247 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[22m<class 'NoneType'> self.keys=None\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.252 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[22mtype(read_df)=<class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.252 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[22mread_df=      key  value\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.548 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[22mfrom pyarrow import HadoopFileSystem\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.548 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[22m0   first      1\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.549 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[22m1  second      2\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.549 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[22m2   third      3\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.549 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[22m3  fourth      4\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.549 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[22m4  secret     42\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.553 \u001b[0m\u001b[32m[1652893702986250/start/1 (pid 36099)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:25.564 \u001b[0m\u001b[32m[1652893702986250/end/2 (pid 36108)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:26.889 \u001b[0m\u001b[32m[1652893702986250/end/2 (pid 36108)] \u001b[0m\u001b[22m/Users/talebz/miniconda/envs/py39/lib/python3.9/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:27.989 \u001b[0m\u001b[32m[1652893702986250/end/2 (pid 36108)] \u001b[0m\u001b[22mdone!\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:28.323 \u001b[0m\u001b[32m[1652893702986250/end/2 (pid 36108)] \u001b[0m\u001b[22mfrom pyarrow import HadoopFileSystem\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:28.327 \u001b[0m\u001b[32m[1652893702986250/end/2 (pid 36108)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-05-18 10:08:28.331 \u001b[0m\u001b[1mDone!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!CONTEXT=ONLINE python 5_consistent_flow.py --no-pylint run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744fea1-3af1-4525-b2d7-cb6b9e44b7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30e0bdcbdb114e5bde736486fe320a5d355d24f216b221497c98cba7520ddf9b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
